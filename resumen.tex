\chapter*{Resumen}
% \addcontentsline{toc}{chapter}{Resumen}


% \chapter*{\hypertarget{resumen}{Resumen}}
% \addcontentsline{toc}{chapter}{
% \protect\hyperlink{resumen}{Resumen}%
% }


El proceso de aprendizaje de juego ficticio, propuesto por primera vez por Brown en 1951 \cite{brown:1951} como un método para encontrar equilibrios de un juego finito de suma cero \cite{libro:rubinstein} a través de la repetición de este en un proceso iterativo, nos provee una posible racionalización a través de la cuál los jugadores pueden llegar a un equilibrio de Nash. Brown propuso dos variantes de juego ficticio: simultaneo y alternante, que se diferencian en la información que en cada iteración tienen los jugadores al momento de tomar su decisión.

Desde la teoría de juegos algorítmica, la utilidad del juego ficticio fue cuestionada en publicaciones que argumentan que si bien el proceso converge, puede requerir una cantidad de iteraciones exponencial en el tamaño de representación del juego y es por tanto menos eficiente que otros métodos para encontrar equilibrios de Nash, como las mecánicas de no arrepentimiento o la resolución del problema de optimización lineal equivalente\falta{citar}. Sin embargo, estas publicaciones se refieren solo al juego ficticio simultaneo. 

En este trabajo, extenderemos el estudio realizado en 2013 por Brandt, Fischer y Harrenstein sobre la velocidad de convergencia del juego ficticio simultaneo a la variante alternante y aportaremos algunos resultados que indican que esta variante podría tener una utilidad práctica superior a su contraparte simultanea como mecanismo para encontrar equilibrios de Nash puros.